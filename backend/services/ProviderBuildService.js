/**
 * ProviderBuildService - DEB â†’ Docker Conversion Service
 * 
 * Builds Docker images from vendor .deb packages to create compliant
 * Hyperspace Provider Modules that can be deployed via HER.
 * 
 * Security:
 * - .deb packages are ONLY installed inside Docker images, never on host
 * - runCommand is stored as JSON array to prevent injection
 * - License files are encrypted before storage
 * - Build contexts are cleaned after completion
 */

import { exec, spawn } from 'child_process';
import { promisify } from 'util';
import fs from 'fs';
import path from 'path';
import crypto from 'crypto';
import { v4 as uuidv4 } from 'uuid';

const execAsync = promisify(exec);

// Build configuration
const BUILD_DIR = process.env.PROVIDER_BUILD_DIR || path.join(process.cwd(), 'provider-builds');
const REGISTRY_URL = process.env.PROVIDER_REGISTRY_URL || 'ghcr.io/hyperspace-ai/providers';
const REGISTRY_USERNAME = process.env.PROVIDER_REGISTRY_USERNAME || '';
const REGISTRY_PASSWORD = process.env.PROVIDER_REGISTRY_PASSWORD || '';
const SECRET_KEY = process.env.PROVIDER_SECRET_KEY || 'dev-secret-key-change-in-production';

// Ensure build directory exists
if (!fs.existsSync(BUILD_DIR)) {
  fs.mkdirSync(BUILD_DIR, { recursive: true });
}

/**
 * Generate Dockerfile template for provider module
 */
function generateDockerfile(config) {
  const {
    ubuntuBase = '22.04',
    runCommandJson,
    requiresGpu = false,
  } = config;

  const gpuSection = requiresGpu ? `
# GPU Support (NVIDIA CUDA)
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility
` : '';

  return `# Auto-generated by Hyperspace Conversion Service
# Provider Module: ${config.displayName} v${config.version}
# Generated: ${new Date().toISOString()}

FROM ubuntu:${ubuntuBase}

ARG DEBIAN_FRONTEND=noninteractive

# Base dependencies
RUN apt-get update && apt-get install -y \\
    ca-certificates \\
    curl \\
    jq \\
    tini \\
    gnupg \\
    && rm -rf /var/lib/apt/lists/*

# Add NodeSource repo for Node.js 18 (required by many providers)
RUN curl -fsSL https://deb.nodesource.com/setup_18.x | bash - \\
    && apt-get install -y nodejs \\
    && rm -rf /var/lib/apt/lists/*

# Install MQTT client library for trajectory publishing
RUN npm install -g mqtt
${gpuSection}
# Install vendor .deb packages
COPY *.deb /tmp/
RUN apt-get update && \\
    apt-get install -y /tmp/*.deb || true && \\
    apt-get install -f -y && \\
    rm -rf /var/lib/apt/lists/* /tmp/*.deb

# Create data directory for deployment config
RUN mkdir -p /data && chmod 755 /data

# Copy entrypoint script
COPY entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

# Create non-root user for security
RUN useradd -m -s /bin/bash -u 1000 provider && \\
    chown -R provider:provider /data

USER provider
WORKDIR /data

# Environment variables (set at runtime)
ENV MQTT_BROKER=mqtt://localhost:1883
ENV MQTT_TOPIC=hyperspace/trajectories
ENV MQTT_QOS=1
ENV EDGE_ID=
ENV VENUE_ID=
ENV CONFIG_FILE=/config/extrinsics.json

# Health check (optional)
# HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\
#   CMD curl -sf http://localhost:9999/health || exit 1

ENTRYPOINT ["/usr/bin/tini", "--", "/entrypoint.sh"]
`;
}

/**
 * Generate entrypoint script that reads deployment config and runs provider
 */
function generateEntrypoint(config) {
  const { runCommandJson } = config;
  
  // Parse run command as JSON array for security
  let runCommand;
  try {
    runCommand = JSON.parse(runCommandJson);
    if (!Array.isArray(runCommand)) {
      throw new Error('runCommand must be a JSON array');
    }
  } catch (err) {
    throw new Error(`Invalid runCommand format: ${err.message}`);
  }

  // Escape for shell script
  const cmdArray = runCommand.map(arg => `"${arg.replace(/"/g, '\\"')}"`).join(' ');

  return `#!/bin/bash
# Hyperspace Provider Module Entrypoint
# Auto-generated by Conversion Service

set -e

echo "[HER Provider] Starting ${config.displayName} v${config.version}"
echo "[HER Provider] EDGE_ID: \${EDGE_ID}"
echo "[HER Provider] VENUE_ID: \${VENUE_ID}"
echo "[HER Provider] MQTT_BROKER: \${MQTT_BROKER}"
echo "[HER Provider] MQTT_TOPIC: \${MQTT_TOPIC}"
echo "[HER Provider] CONFIG_FILE: \${CONFIG_FILE}"

# Config file is optional - don't block startup
if [ -f "\${CONFIG_FILE}" ]; then
  echo "[HER Provider] Config file found: \${CONFIG_FILE}"
else
  echo "[HER Provider] No config file, using environment variables"
fi

# Parse deployment config if available
if [ -f "\${CONFIG_FILE}" ]; then
  echo "[HER Provider] Loading config from \${CONFIG_FILE}"
  
  # Extract values from deployment.json using jq
  if command -v jq &> /dev/null; then
    export EDGE_ID=\$(jq -r '.edgeId // empty' "\${CONFIG_FILE}" 2>/dev/null || echo "\${EDGE_ID}")
    export VENUE_ID=\$(jq -r '.venueId // empty' "\${CONFIG_FILE}" 2>/dev/null || echo "\${VENUE_ID}")
    
    # Extract MQTT config
    MQTT_BROKER_CFG=\$(jq -r '.mqtt.broker // empty' "\${CONFIG_FILE}" 2>/dev/null)
    MQTT_TOPIC_CFG=\$(jq -r '.mqtt.topic // empty' "\${CONFIG_FILE}" 2>/dev/null)
    
    [ -n "\${MQTT_BROKER_CFG}" ] && export MQTT_BROKER="\${MQTT_BROKER_CFG}"
    [ -n "\${MQTT_TOPIC_CFG}" ] && export MQTT_TOPIC="\${MQTT_TOPIC_CFG}"
  fi
fi

# MQTT_TOPIC is already set correctly via environment, don't modify it
echo "[HER Provider] MQTT topic: \${MQTT_TOPIC}"
echo "[HER Provider] Executing provider command..."

# Execute the provider binary
exec ${cmdArray}
`;
}

/**
 * Build Docker image from .deb files
 */
export async function buildProviderImage(buildId, config, debFilePaths, db) {
  const buildContextPath = path.join(BUILD_DIR, buildId);
  let logs = [];
  
  const log = (message) => {
    const timestamp = new Date().toISOString();
    const entry = `[${timestamp}] ${message}`;
    logs.push(entry);
    console.log(`[Build ${buildId}] ${message}`);
    
    // Update logs in database
    try {
      db.prepare('UPDATE provider_builds SET logs = ? WHERE id = ?')
        .run(logs.join('\n'), buildId);
    } catch (err) {
      console.error('Failed to update build logs:', err.message);
    }
  };

  try {
    // Update status to building
    db.prepare('UPDATE provider_builds SET status = ?, started_at = ? WHERE id = ?')
      .run('building', new Date().toISOString(), buildId);

    log('Creating build context directory...');
    fs.mkdirSync(buildContextPath, { recursive: true });

    // Copy .deb files to build context
    log(`Copying ${debFilePaths.length} .deb file(s) to build context...`);
    for (const debPath of debFilePaths) {
      const filename = path.basename(debPath);
      fs.copyFileSync(debPath, path.join(buildContextPath, filename));
      log(`  - ${filename}`);
    }

    // Generate Dockerfile
    log('Generating Dockerfile...');
    const dockerfile = generateDockerfile(config);
    fs.writeFileSync(path.join(buildContextPath, 'Dockerfile'), dockerfile);

    // Generate entrypoint script
    log('Generating entrypoint.sh...');
    const entrypoint = generateEntrypoint(config);
    fs.writeFileSync(path.join(buildContextPath, 'entrypoint.sh'), entrypoint);

    // Build image tag
    const imageTag = `${REGISTRY_URL}/${config.providerId}:${config.version}`;
    log(`Building Docker image: ${imageTag}`);

    // Check if Docker is available
    try {
      await execAsync('docker --version');
    } catch (err) {
      throw new Error('Docker is not available on this system');
    }

    // Build the image
    const buildCmd = `docker build -t ${imageTag} ${buildContextPath}`;
    log(`Running: ${buildCmd}`);
    
    const { stdout: buildOutput, stderr: buildError } = await execAsync(buildCmd, {
      timeout: 600000, // 10 minute timeout
      maxBuffer: 50 * 1024 * 1024, // 50MB buffer for large builds
    });
    
    if (buildOutput) log(buildOutput);
    if (buildError) log(`STDERR: ${buildError}`);

    log('Docker image built successfully');

    // Get image digest
    log('Getting image digest...');
    const { stdout: digestOutput } = await execAsync(
      `docker inspect --format='{{index .RepoDigests 0}}' ${imageTag} 2>/dev/null || docker inspect --format='{{.Id}}' ${imageTag}`
    );
    const imageDigest = digestOutput.trim();
    log(`Image digest: ${imageDigest}`);

    // Try to push to registry if credentials are available
    let pushed = false;
    let digestRef = imageDigest;

    if (REGISTRY_USERNAME && REGISTRY_PASSWORD) {
      log('Pushing image to registry...');
      db.prepare('UPDATE provider_builds SET status = ? WHERE id = ?')
        .run('pushing', buildId);

      try {
        // Login to registry
        await execAsync(
          `echo "${REGISTRY_PASSWORD}" | docker login ${REGISTRY_URL.split('/')[0]} -u "${REGISTRY_USERNAME}" --password-stdin`
        );
        
        // Push image
        const { stdout: pushOutput } = await execAsync(`docker push ${imageTag}`, {
          timeout: 600000,
        });
        log(pushOutput);
        
        // Get pushed digest
        const { stdout: pushedDigest } = await execAsync(
          `docker inspect --format='{{index .RepoDigests 0}}' ${imageTag}`
        );
        digestRef = pushedDigest.trim();
        pushed = true;
        log(`Image pushed successfully: ${digestRef}`);
      } catch (pushErr) {
        log(`WARNING: Failed to push image: ${pushErr.message}`);
        log('Image is available locally but not pushed to registry');
      }
    } else {
      log('WARNING: No registry credentials configured, image not pushed');
      log('Set PROVIDER_REGISTRY_USERNAME and PROVIDER_REGISTRY_PASSWORD to enable push');
    }

    // Update build status to succeeded
    db.prepare(`
      UPDATE provider_builds 
      SET status = ?, docker_image_tag = ?, docker_image_digest = ?, completed_at = ?, logs = ?
      WHERE id = ?
    `).run('succeeded', imageTag, digestRef, new Date().toISOString(), logs.join('\n'), buildId);

    // Update provider with image reference
    db.prepare(`
      UPDATE algorithm_providers 
      SET docker_image_ref = ?, docker_image_digest = ?, updated_at = ?
      WHERE id = ?
    `).run(imageTag, digestRef, new Date().toISOString(), config.id);

    log('Build completed successfully!');

    return {
      success: true,
      buildId,
      imageTag,
      imageDigest: digestRef,
      pushed,
      logs: logs.join('\n'),
    };

  } catch (err) {
    log(`ERROR: ${err.message}`);
    
    // Update build status to failed
    db.prepare(`
      UPDATE provider_builds 
      SET status = ?, error_message = ?, completed_at = ?, logs = ?
      WHERE id = ?
    `).run('failed', err.message, new Date().toISOString(), logs.join('\n'), buildId);

    return {
      success: false,
      buildId,
      error: err.message,
      logs: logs.join('\n'),
    };

  } finally {
    // Clean up build context
    try {
      if (fs.existsSync(buildContextPath)) {
        fs.rmSync(buildContextPath, { recursive: true, force: true });
        console.log(`[Build ${buildId}] Cleaned up build context`);
      }
    } catch (cleanupErr) {
      console.error(`[Build ${buildId}] Failed to cleanup:`, cleanupErr.message);
    }
  }
}

/**
 * Encrypt a secret value for storage
 */
export function encryptSecret(value) {
  const iv = crypto.randomBytes(16);
  const key = crypto.scryptSync(SECRET_KEY, 'salt', 32);
  const cipher = crypto.createCipheriv('aes-256-cbc', key, iv);
  let encrypted = cipher.update(value, 'utf8', 'hex');
  encrypted += cipher.final('hex');
  return iv.toString('hex') + ':' + encrypted;
}

/**
 * Decrypt a secret value from storage
 */
export function decryptSecret(encryptedValue) {
  const [ivHex, encrypted] = encryptedValue.split(':');
  const iv = Buffer.from(ivHex, 'hex');
  const key = crypto.scryptSync(SECRET_KEY, 'salt', 32);
  const decipher = crypto.createDecipheriv('aes-256-cbc', key, iv);
  let decrypted = decipher.update(encrypted, 'hex', 'utf8');
  decrypted += decipher.final('utf8');
  return decrypted;
}

/**
 * Validate .deb file
 */
export function validateDebFile(filePath) {
  if (!fs.existsSync(filePath)) {
    return { valid: false, error: 'File does not exist' };
  }

  const stats = fs.statSync(filePath);
  
  // Check file size (max 500MB)
  const maxSize = 500 * 1024 * 1024;
  if (stats.size > maxSize) {
    return { valid: false, error: `File too large: ${stats.size} bytes (max: ${maxSize})` };
  }

  // Check file extension
  if (!filePath.toLowerCase().endsWith('.deb')) {
    return { valid: false, error: 'File must have .deb extension' };
  }

  // Basic magic number check for .deb files (ar archive)
  const buffer = Buffer.alloc(8);
  const fd = fs.openSync(filePath, 'r');
  fs.readSync(fd, buffer, 0, 8, 0);
  fs.closeSync(fd);

  // .deb files start with "!<arch>\n"
  const magic = buffer.toString('ascii');
  if (!magic.startsWith('!<arch>')) {
    return { valid: false, error: 'Invalid .deb file format' };
  }

  return { valid: true, size: stats.size };
}

/**
 * Get build status
 */
export function getBuildStatus(buildId, db) {
  return db.prepare('SELECT * FROM provider_builds WHERE id = ?').get(buildId);
}

/**
 * Get all builds for a provider
 */
export function getProviderBuilds(providerId, db) {
  return db.prepare(`
    SELECT * FROM provider_builds 
    WHERE provider_id = ? 
    ORDER BY created_at DESC
  `).all(providerId);
}

export default {
  buildProviderImage,
  encryptSecret,
  decryptSecret,
  validateDebFile,
  getBuildStatus,
  getProviderBuilds,
  generateDockerfile,
  generateEntrypoint,
};
